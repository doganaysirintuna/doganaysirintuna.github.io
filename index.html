<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Doganay Sirintuna</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css">
	</head>
	<body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="#top">About</a></li>
					<li><a href="#experience">Experience</a></li>
					<li><a href="#education">Education</a></li>
					<li><a href="#projects">Publications</a></li>
				</ul>
			</nav>

		<!-- Home -->
			<article id="top" class="wrapper style1">
				<div class="container">
					<div class="row">
						<div class="col-4 col-5-large col-12-medium">
							<div class="flip-circle-container" onclick="this.classList.toggle('flip-active')">
							  <div class="flip-circle-inner">
								<div class="flip-circle-front">
								  <img src="images/Doganay.jpeg" alt="Front Image" />
								</div>
								<div class="flip-circle-back">
								  <img src="images/Doganay1.jpg" alt="Back Image" />
								</div>
							  </div>
							</div>
						  </div>
						<div class="col-8 col-7-large col-12-medium">
							<header>
								<h1><strong>Doganay Sirintuna</strong></h1>
							</header>
							<!-- <p>And this is <strong>Miniport</strong>, a free, fully responsive HTML5 site template designed by <a href="http://twitter.com/ajlkn">AJ</a> for <a href="http://html5up.net">HTML5 UP</a> &amp; released under the <a href="http://html5up.net/license">CCA license</a>.</p> -->
							<ul class="social">
								<li><a href="mailto:doganaysirintuna@gmail.com" class="fa fa-envelope" target="_blank" rel="noopener noreferrer" aria-label="Email"></a></li>
								<li><a href="https://www.linkedin.com/in/doganay-sirintuna/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
								<li><a href="https://scholar.google.com/citations?user=ZCjO4IAAAAAJ&hl" class="ai ai-google-scholar"></a></li>
								<li><a href="https://www.researchgate.net/profile/Doganay-Sirintuna" class="ai ai-researchgate" target="_blank" rel="noopener noreferrer" aria-label="ResearchGate"></a></li>
							</ul>
						</div>
					</div>
				</div>
			</article>



			<!-- Experience  -->
			<hr class="m-0" />
			<section class="resume-section education-section" id="experience">
			  <div class="resume-section-content">
				<h2 class="mb-5">Experience</h2>
			
				<div class="timeline">
					<div class="timeline-item">
						<div class="card">
							<div class="text-block">
								<h3>Ph.D. Student</h3>
								<div class="logo-row">
									<img src="images/iit.jpg" class="institution-logo" />
									<img src="images/unige.png" class="institution-logo" />
									<div class="institution">Italian Institute of Technology / University of Genoa</div>
								</div>
							</div>
							<div class="date-location-row">
								<span class="date"><i class="fas fa-calendar-alt"></i>Nov 2022 - Nov 2025 (Expected)</span>
								<span class="location"><i class="fas fa-map-marker-alt"></i> Genoa, IT</span>
							</div>
							<p class="description">
								<strong>Supervisor: </strong> <a href="https://scholar.google.com/citations?user=1hKOgRoAAAAJ&hl">Dr. Arash Ajoudani</a>
							</p>
						</div>
					</div>


			
					<div class="timeline-item">
						<div class="card">
							<div class="text-block">
								<h3>Research Fellow</h3>
								<div class="logo-row">
									<img src="images/iit.jpg" class="institution-logo" />
									<div class="institution">Italian Institute of Technology</div>
								</div>
							</div>
							<div class="date-location-row">
								<span class="date"><i class="fas fa-calendar-alt"></i>Jun 2021 - Sep 2022</span>
								<span class="location"><i class="fas fa-map-marker-alt"></i> Genoa, IT</span>
							</div>
							<p class="description">
								Add here.<br>
								<strong>Supervisor: </strong> <a href="https://scholar.google.com/citations?user=1hKOgRoAAAAJ&hl">Dr. Arash Ajoudani</a>
							</p>
						</div>
					</div>
			
					<div class="timeline-item">
						<div class="card">

							<div class="text-block">
								<h3>Research and Teaching Assistant</h3>
								<div class="logo-row">
									<img src="images/kocuni.jpg" class="institution-logo" />
									<div class="institution">Koc University</div>
								</div>
							</div>

							<div class="date-location-row">
								<span class="date"><i class="fas fa-calendar-alt"></i>Sep 2018 - Jul 2020</span>
								<span class="location"><i class="fas fa-map-marker-alt"></i> Istanbul, TR</span>
							</div>
							<p class="description">
							Courses: Robotics, Dynamic Modeling and Control, Computer-Based Modeling and Simulation, Manufacturing Processes, Mechanical Engineering Design Project							
							</p>
						</div>
					</div>

					
					<div class="timeline-item">
						<div class="card">

							<div class="text-block">
								<h3>Tutor</h3>
								<div class="logo-row">
									<img src="images/kocuni.jpg" class="institution-logo" />
									<div class="institution">Koc University</div>
								</div>
							</div>
							<div class="date-location-row">
								<span class="date"><i class="fas fa-calendar-alt"></i>2014 - 2018</span>
								<span class="location"><i class="fas fa-map-marker-alt"></i> Istanbul, TR</span>
							</div>
							<p class="description">
							Tutored in Koc University Office of Learning and Teaching. <br>
							Courses: Introduction to Mechanical Engineering, Statics and Mechanics of Materials, Numerical Methods for Mechanical Engineering, Engineering Materials
							</p>
							</div>
						</div>
					</div>
			  </div>
			</section>


			<!-- Education  -->
			<hr class="m-0" />
			<section class="resume-section education-section" id="education">
			  <div class="resume-section-content">
				<h2 class="mb-5">Education</h2>
			
				<div class="timeline">

				<div class="timeline-item">
					<div class="card">
						<div class="text-block">
							<h3>Ph.D. in Advanced and Humanoid Robotics</h3>
							<div class="logo-row">
								<img src="images/iit.jpg" class="institution-logo" />
								<img src="images/unige.png" class="institution-logo" />
								<div class="institution">Italian Institute of Technology / University of Genoa</div>
							</div>
						</div>
						<div class="date-location-row">
							<span class="date"><i class="fas fa-calendar-alt"></i>Nov 2022- Nov 2025</span>
							<span class="location"><i class="fas fa-map-marker-alt"></i> Genoa, IT</span>
						</div>


						<p class="description">
							<strong>Supervisor: </strong> <a href="https://scholar.google.com/citations?user=1hKOgRoAAAAJ&hl">Dr. Arash Ajoudani</a>
						</p>
						</div>
					</div>



				  <div class="timeline-item">
					<div class="card">

						<div class="text-block">
							<h3>M.Sc. in Robotics Engineering</h3>
							<div class="logo-row">
								<img src="images/kocuni.jpg" class="institution-logo" />
								<div class="institution">Koc University</div>
							</div>
						</div>
						<div class="date-location-row">
							<span class="date"><i class="fas fa-calendar-alt"></i>Sep 2018 - Jul 2020</span>
							<span class="location"><i class="fas fa-map-marker-alt"></i> Istanbul, TR</span>
						</div>
						<p class="description">
							Full-Merit Scholarship, GPA: 4.00<br>
							Graduate School of Sciences and Engineering Academic Excellence Award<br>
							Graduation with "Magna Cum Laude" (with high honor)<br>
							<strong>Supervisor: </strong> <a href="https://scholar.google.com/citations?user=Oz32f6gAAAAJ&hl"> Prof. Dr. Cagatay Basdogan</a>
						</p>
					</div>
				  </div>
			
				  <div class="timeline-item">

					<div class="card">

						<div class="text-block">
							<h3>B.Sc. in Mechanical Engineering</h3>
							<div class="logo-row">
								<img src="images/kocuni.jpg" class="institution-logo" />
								<div class="institution">Koc University</div>
							</div>
						</div>


						<div class="date-location-row">
							<span class="date"><i class="fas fa-calendar-alt"></i>Sep 2013 - Jul 2018</span>
							<span class="location"><i class="fas fa-map-marker-alt"></i> Istanbul, TR</span>
						</div>
						<p class="description">
							Full-Merit Scholarship, GPA: 3.85<br>
							Ranked as 2nd in the class<br>
							Graduation with "Magna Cum Laude" (with high honor)<br>
						</p>
					</div>
				  </div>
				</div>
			  </div>
			</section>




		  <!-- Projects -->
		  <hr class="m-0" />
		  <section class="resume-section projects-section" id="projects">
		  <div class="resume-section-content">
			  <h2 class="mb-5">Publications</h2>

			  <div class="project">
				<h3>Journal Articles</h3>
				<!-- Work 1 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Pushing in the Dark: A Reactive Pushing Strategy for Mobile Robots Using Tactile Feedback</strong></p>
						<p class="author">Idil Ozdamar*, <strong>Doganay Sirintuna*</strong>, Robin Arbaud, and Arash Ajoudani</p>
						<p>Tactile-driven reactive pushing strategy for real-time mobile manipulation without prior knowledge of object, robot, or environment properties. 
						This method dynamically adjusts robot motion based on the object’s contact location, enabling effective manipulation in unstructured, real-world environments.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/document/10556715" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE Robotics and Automation Letters</em>, 2024</p>
						</div>
					</div>
					<div class="video-wrapper">
						<iframe 
						src="https://www.youtube.com/embed/3-zXarpVezA" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin"
						allowfullscreen>
						</iframe>
					</div>
				</div>
			</div>

			<div class="project">
				<!-- Work 2 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Enhancing human–robot collaborative transportation through obstacle-aware vibrotactile warning and virtual fixtures</strong></p>
						<p class="author"><strong>Doganay Sirintuna*</strong>, Theodora Kastritsi*, Idil Ozdamar*, Juan M Gandarias, and Arash Ajoudani</p>
						<p>Situational awareness framework with vibrotactile feedback and virtual fixtures for safe human-robot collaborative transportation. 
						By delivering real-time obstacle warnings and enforcing mobility constraints, it helps operators navigate complex environments more safely and efficiently.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://www.sciencedirect.com/science/article/pii/S0921889024001088" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>Robotics and Autonomous Systems</em>, 2024</p>
						</div>
					</div>
					<div class="video-wrapper">
						<iframe 
						src="https://www.youtube.com/embed/BRvDC8XLOWM" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin"
						allowfullscreen>
						</iframe>
					</div>
				</div>
			</div>


			<div class="project">

				<!-- Work 3 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>An Object Deformation-Agnostic Framework for Human-Robot Collaborative Transportation</strong></p>
						<p class="author"><strong>Doganay Sirintuna</strong>, Alberto Giammarino, and Arash Ajoudani</p>
						<p>Adaptive object deformability-agnostic human-robot collaborative transportation framework that combines the haptic information transferred through the object with the human kinematic information to generate reactive whole-body motions on a mobile collaborative robot. 
						Furthermore, it allows rotating the objects based on an algorithm that detects the human rotation intention using the torso and hand movements.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/10081043" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE Transactions on Automation Science and Engineering</em>, 2022</p>
						</div>
					</div>
					<div class="video-wrapper">
						<iframe 
						src="https://www.youtube.com/embed/oyfUkYj5WYw" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin"
						allowfullscreen>
						</iframe>
					</div>
				</div>
			</div>

			<h3>Conference Proceedings</h3>

			<div class="project">
				<!-- Work 1 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Robot-assisted navigation for visually impaired through adaptive impedance and path planning</strong></p>
						<p class="author">Pietro Balatti*, Idil Ozdamar*, <strong>Doganay Sirintuna*</strong>, Luca Fortini, Mattia Leonori, Juan M Gandarias, and Arash Ajoudani</p>
						<p>Framework for guiding visually impaired individuals through unfamiliar environments using a mobile manipulator with coordinated obstacle avoidance and human guidance. 
						The system employs LiDAR-based leg tracking and adaptive pulling, using impedance control to dynamically adjust the robotic arm’s movements and guide the user back to the intended path for safe and intuitive navigation.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/10611071" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024</p>
						</div>
					</div>
					<div class="video-wrapper">
						<iframe 
						src="https://www.youtube.com/embed/B94n3QjdnJE" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin"
						allowfullscreen>
						</iframe>
					</div>
				</div>
			</div>

			<div class="project">
				<!-- Work 2 -->
				  <div class="two-column">
					<div class="explanation">
						<p><strong>Carrying the uncarriable: a deformation-agnostic and human-cooperative framework for unwieldy objects using multiple robots</strong></p>
						<p class="author"><strong>Doganay Sirintuna</strong>, Idil Ozdamar, and Arash Ajoudani</p> 
						<p>Object deformability-agnostic framework for co-carrying tasks shared between a person and multiple robots. 
						The approach allows full control of the co-carrying trajectories by the person using haptic feedback from the object combined with human motion information..</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/10160677" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023</p>
						</div>
					</div>
					<div class="video-wrapper">
					  <iframe src="https://www.youtube.com/embed/Q3sA6YzTaaE" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin" 
						allowfullscreen>
					  </iframe>
					</div>
				</div>
			</div>

			<div class="project">
				<!-- Work 3 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Human-robot collaborative carrying of objects with unknown deformation characteristics</strong></p>
						<p class="author"><strong>Doganay Sirintuna</strong>, Alberto Giammarino, and Arash Ajoudani</p> 
						<p>Adaptive control framework for human–robot collaborative transportation of objects with unknown deformation behavior. 
							The system combines haptic and human motion information to generate reactive whole-body robot motions, enabling intuitive and effective co-transportation across varying object deformabilities..</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/9981948" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2022</p>
						</div>
					</div>
					<div class="video-wrapper">
					  <iframe src="https://www.youtube.com/embed/ounQmCdYlC4" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin" 
						allowfullscreen>
					  </iframe>
					</div>
				</div>
			</div>

			<div class="project">
				<!-- Work 4 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Detecting human motion intention during pHRI using artificial neural networks trained by EMG signals</strong></p>
						<p class="author"><strong>Doganay Sirintuna*</strong>, Idil Ozdamar*, Yusuf Aydin, and Cagatay Basdogan</p> 
						<p>Intention-aware admittance control architecture for physical human-robot interaction using EMG-based direction classification. 
						An artificial neural network predicts human motion intent from arm muscle signals and modulates the cobot's admittance controller in real time, reducing undesired movements without increasing task completion time.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/9223438" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</em>, 2020</p>
						</div>
					</div>
					<div class="video-wrapper">
					  <iframe src="https://www.youtube.com/embed/8F1HCEKEr4s" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin" 
						allowfullscreen>
					  </iframe>
					</div>
				</div>
			</div>

			<div class="project">			
				<!-- Work 5 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>A variable-fractional order admittance controller for pHRI</strong></p>
						<p class="author"><strong>Doganay Sirintuna*</strong>, Yusuf Aydin*, Ozan Caldiran, Ozan Tokatli, Volkan Patoglu, and Cagatay Basdogan</p> 
						<p>Fractional-order variable admittance controller for transparent and stable physical human-robot interaction in manufacturing tasks. 
						Compared to baseline controllers, the proposed method improves transparency without compromising stability, and integrates with augmented reality to enhance human sensory feedback during precision operations like drilling.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/9197288" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020</p>
						</div>
					</div>
					<div class="video-wrapper">
						<iframe src="https://www.youtube.com/embed/VvPMVEHXBMk" 
						title="YouTube video player" 
						frameborder="0" 
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
						referrerpolicy="strict-origin-when-cross-origin" 
						allowfullscreen>
						</iframe>
					</div>
				</div>
			</div>

	
			<h3>Contributed Works</h3>

			<div class="project">			
				<!-- Work 1 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>A Non-parametric Approach to Exploring and Quantifying the Information Flow in Human-Robot Collaboration</strong></p>
						<p class="author">Gustavo Jose Giardini Lahr, <strong>Doganay Sirintuna</strong>, Francesco Tassi, Heni Ben Amor, Arash Ajoudani</p>
						<p>Information-theoretic framework for analyzing non-verbal communication in physical human-robot interaction. 
						Using entropy-based measures, the approach quantifies information flow, leadership, and coupling between agents, revealing key communication dynamics in collaborative tasks.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://dl.acm.org/doi/10.1145/3744755" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>ACM Transactions on Human-Robot Interaction</em>, 2024</p>
						</div>
					</div>
					<div class="video-wrapper">
						<img src="images/Gustavo_paper.jpg" alt="Project preview" style="width: 100%; border-radius: 8px;">
					</div>
				</div>
			</div>

			<div class="project">			
				<!-- Work 2 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Evaluating leadership roles in human-robot interaction via highly dynamic collaborative tasks</strong></p>
						<p class="author">Gustavo Jose Giardini Lahr, Francesco Tassi, <strong>Doganay Sirintuna</strong>, Heni Ben Amor, and Arash Ajoudani</p>
						<p>Study of non-verbal communication and leadership dynamics in human-robot interaction through a collaborative object-catching task. 
						Comparison between human-human and human-robot interactions across control modalities reveals the influence of leadership roles in highly dynamic tasks.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/10731284" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE International Conference on Robot and Human Interactive Communication (ROMAN)</em>, 2024</p>
						</div>
					</div>
					<div class="video-wrapper">
						<img src="images/Tassi_paper.jpg" alt="Project preview" style="width: 100%; border-radius: 3px; display: block; margin: 0 auto;">
					</div>
				</div>
			</div>
	
			<div class="project">			
				<!-- Work 3 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>A Novel Haptic Feature Set for the Classification of Interactive Motor Behaviors in Collaborative Object Transfer</strong></p>
						<p class="author">Zaid Al-Saadi, <strong>Doganay Sirintuna</strong>, Ayse Kucukyilmaz, and Cagatay Basdogan</p>
						<p>Haptic-based classification of interaction patterns in physical human–human collaboration during joint object transportation. 
						Using force and torque data, the study identifies cooperative and conflicting behaviors during translational and rotational movements.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://ieeexplore.ieee.org/abstract/document/9241412" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>IEEE Transactions on Haptics</em>, 2020</p>
						</div>
					</div>
					<div class="video-wrapper">
						<img src="images/Zaid.png" alt="Project preview" style="width: 100%; border-radius: 8px; display: block; margin: 0 auto;">
					</div>
				</div>
			</div>

			<div class="project">			
				<!-- Work 4 -->
				<div class="two-column">
					<div class="explanation">
						<p><strong>Towards collaborative drilling with a cobot using admittance controller</strong></p>
						<p class="author">Yusuf Aydin, <strong>Doganay Sirintuna</strong>, and Cagatay Basdogan</p>
						<p>Methodology for designing admittance controllers balancing stability and transparency in physical human-robot interaction. 
						Applied to a collaborative drilling task with a KUKA LBR IIWA 7 R800 cobot and augmented reality interface, the approach identifies optimal controller parameters to enhance task performance and operator guidance.</p>
						<div style="display: flex; align-items: center; gap: 16px;">
							<a href="https://journals.sagepub.com/doi/abs/10.1177/0142331220934643" target="_blank" style="display: inline-flex; align-items: center; justify-content: center; background-color: #ff6600; color: white; padding: 6px 12px; border-radius: 12px; 
							text-decoration: none; font-weight: 600; font-size: 13px; gap: 10px;">
								<i class="fas fa-file-alt" style="margin-right: 8px;"></i> Paper link
							</a>
							<p class="journal" style="margin: 0;"><em>Transactions of the Institute of Measurement and Control</em>, 2020</p>
						</div>
					</div>
					<div class="video-wrapper">
						<img src="images/Yusuf.jpg" alt="Project preview" style="width: 100%; border-radius: 8px; display: block; margin: 0 auto;">
					</div>
				</div>
			</div>

			  <!-- Add more project blocks as needed -->
		  </div> <!-- End of resume-section-content -->

		<!-- Portfolio -->
			<!-- <article id="portfolio" class="wrapper style3">
				<div class="container">
					<header>
						<h2>Here’s some stuff I made recently.</h2>
						<p>Proin odio consequat  sapien vestibulum consequat lorem dolore feugiat.</p>
					</header>
					<div class="row">
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic01.jpg" alt="" /></a>
								<h3><a href="#">Magna feugiat</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic02.jpg" alt="" /></a>
								<h3><a href="#">Veroeros primis</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic03.jpg" alt="" /></a>
								<h3><a href="#">Lorem ipsum</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic04.jpg" alt="" /></a>
								<h3><a href="#">Tempus dolore</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic05.jpg" alt="" /></a>
								<h3><a href="#">Feugiat aliquam</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="#" class="image featured"><img src="images/pic06.jpg" alt="" /></a>
								<h3><a href="#">Sed amet ornare</a></h3>
								<p>Ornare nulla proin odio consequat.</p>
							</article>
						</div>
					</div>
				</div>
			</article> -->


					<!-- Work -->
			<!-- <article id="work" class="wrapper style2">
				<div class="container">
					<header>
						<h2>Here's all the stuff I do.</h2>
						<p>Odio turpis amet sed consequat eget posuere consequat.</p>
					</header>
					<div class="row aln-center">
						<div class="col-4 col-6-medium col-12-small">
							<section class="box style1">
								<span class="icon featured fa-comments"></span>
								<h3>Consequat lorem</h3>
								<p>Ornare nulla proin odio consequat sapien vestibulum ipsum primis sed amet consequat lorem dolore.</p>
							</section>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<section class="box style1">
								<span class="icon solid featured fa-camera-retro"></span>
								<h3>Lorem dolor tempus</h3>
								<p>Ornare nulla proin odio consequat sapien vestibulum ipsum primis sed amet consequat lorem dolore.</p>
							</section>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<section class="box style1">
								<span class="icon featured fa-thumbs-up"></span>
								<h3>Feugiat posuere</h3>
								<p>Ornare nulla proin odio consequat sapien vestibulum ipsum primis sed amet consequat lorem dolore.</p>
							</section>
						</div>
					</div>
					<footer>
						<p>Lorem ipsum dolor sit sapien vestibulum ipsum primis?</p>
						<a href="#portfolio" class="button large scrolly">See some of my recent work</a>
					</footer>
				</div>
			</article> -->
			
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script>
				let hasFlipped = false;
			  
				function autoFlipOnce() {
				  if (hasFlipped) return;
			  
				  const flipContainer = document.querySelector('.flip-circle-container');
				  if (flipContainer) {
					flipContainer.classList.add('flip-active');
					hasFlipped = true;
				  }
			  
				  // Remove listener after first interaction
				  document.removeEventListener('click', autoFlipOnce);
				  document.removeEventListener('touchstart', autoFlipOnce);
				}
			  
				// Attach to first click or tap
				document.addEventListener('click', autoFlipOnce);
				document.addEventListener('touchstart', autoFlipOnce);
			</script>

	</body>
</html>